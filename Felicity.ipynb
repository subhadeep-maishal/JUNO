{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                ::  Felicity  ::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#----------------------------------------------start JUNO------------------------------------------------------------------ \n",
    "\n",
    "# Generator model\n",
    "def build_generator(latent_dim, output_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(np.prod(output_shape), activation='linear'))\n",
    "    model.add(Reshape(output_shape))\n",
    "    return model\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.8))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.8))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "# RNN model\n",
    "def build_rnn(latent_dim, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(2000, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(LSTM(2000, return_sequences=True))\n",
    "    model.add(LSTM(2000))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "# GAN model\n",
    "def build_gan(generator, discriminator, input_shape):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(Reshape((input_shape[0], input_shape[1])))\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "\n",
    "#----------------------------------------------end JUNO------------------------------------------------------------------ \n",
    "\n",
    "\n",
    "\n",
    "# Potential and example data loading (replace with your own data loading logic)\n",
    "file_path = r'C:\\Users\\Subhadeep Maishal\\Music\\JUP\\test_data\\CBN_INPUT.csv'\n",
    "df = pd.read_csv(file_path, parse_dates=['DATE'])\n",
    "features = df[['AAO', 'AO', 'DMI', 'NAO', 'ONI', 'PDO', 'SOI', 'TNA', 'TSA', 'WHWP', 'WP']]\n",
    "target = df['MEIv2']\n",
    "features = (features - features.min()) / (features.max() - features.min())\n",
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator((features.shape[1], 1))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.2, 0.5), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build and compile the generator\n",
    "latent_dim = 100\n",
    "generator = build_generator(latent_dim, (features.shape[1], 1))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(0.2, 0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build and compile the RNN\n",
    "rnn = build_rnn(latent_dim, (features.shape[1], 1))\n",
    "rnn.compile(loss='mean_squared_error', optimizer=Adam(0.2, 0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build and compile the GAN with RNN\n",
    "discriminator.trainable = False\n",
    "gan_rnn = build_gan(generator, discriminator, (features.shape[1], 1))\n",
    "gan_rnn.compile(loss='binary_crossentropy', optimizer=Adam(0.2, 0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training GAN with RNN\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.randint(0, features.shape[0], half_batch)\n",
    "    real_data = features.iloc[idx].values  # Convert to numpy array\n",
    "\n",
    "    noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "    generated_data = generator.predict(noise)\n",
    "\n",
    "    real_labels = np.ones((half_batch, 1))\n",
    "    fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    valid_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    g_loss = gan_rnn.train_on_batch(noise, valid_labels)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# Generate data using RNN >>\n",
    "num_samples = 420\n",
    "noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "generated_data = generator.predict(noise)\n",
    "synthetic_data = rnn.predict(generated_data.reshape((num_samples, features.shape[1], 1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot actual and generated data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df['DATE'], target, label='Actual', marker='o', color='black')\n",
    "plt.plot(df['DATE'].iloc[-num_samples:], synthetic_data[:, 0], label='Generated', marker='o', color='blue')\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('MEIv2 Values', fontsize=14)\n",
    "plt.title('Actual vs Generated MEIv2 Values Over Time', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae97f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                       ::   Cheers!  ::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938acb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                       ::  Subhadeep  ::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
